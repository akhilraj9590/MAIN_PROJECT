{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "9d8f9c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-257.00793, 143.21645, -63.392902, 45.306725,...</td>\n",
       "      <td>Mayamalavagowla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-342.479, 121.16525, -28.796282, 44.39041, 14...</td>\n",
       "      <td>Mayamalavagowla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-265.17584, 147.72835, -59.28968, 47.248676, ...</td>\n",
       "      <td>Mayamalavagowla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-265.8661, 142.71452, -62.37273, 47.353455, 4...</td>\n",
       "      <td>Mayamalavagowla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-270.8769, 146.13509, -59.109337, 46.9478, 1....</td>\n",
       "      <td>Mayamalavagowla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[-288.0216, 149.35812, -47.245678, 37.415783, ...</td>\n",
       "      <td>Mayamalavagowla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[-354.0573, 141.69968, 26.293093, 13.852002, -...</td>\n",
       "      <td>Mayamalavagowla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[-364.73254, 127.644356, 28.105154, 23.548061,...</td>\n",
       "      <td>Mayamalavagowla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[-358.08014, 125.53306, 32.00193, 22.871235, -...</td>\n",
       "      <td>Mayamalavagowla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[-358.75586, 140.48027, 27.321226, 9.683236, -...</td>\n",
       "      <td>Mayamalavagowla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[-329.88388, 132.13698, 24.247555, 18.087626, ...</td>\n",
       "      <td>Mayamalavagowla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[-301.8801, 77.61273, -43.964954, 6.8427114, -...</td>\n",
       "      <td>Mayamalavagowla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[-310.87204, 68.62663, -43.044067, 2.4750962, ...</td>\n",
       "      <td>Mayamalavagowla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[-302.76172, 74.42201, -47.095207, 5.852565, -...</td>\n",
       "      <td>Mayamalavagowla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[-197.08652, 81.49152, -48.00849, 36.93677, -1...</td>\n",
       "      <td>Mohanam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[-157.275, 95.572685, -55.988686, 30.901611, -...</td>\n",
       "      <td>Mohanam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[-178.47586, 78.64402, -35.6453, 20.774988, -1...</td>\n",
       "      <td>Mohanam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[-177.37201, 85.34112, -41.96415, 44.57123, -2...</td>\n",
       "      <td>Mohanam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[-172.45381, 82.0647, -43.0798, 23.08912, -7.3...</td>\n",
       "      <td>Mohanam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[-179.4202, 85.24829, -47.030994, 33.15376, -1...</td>\n",
       "      <td>Mohanam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[-308.3186, 102.52005, 13.691593, 20.561224, 1...</td>\n",
       "      <td>Mohanam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[-322.12534, 111.55545, 11.61951, 22.521864, 1...</td>\n",
       "      <td>Mohanam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[-330.14243, 118.97464, 11.84664, 25.165697, 7...</td>\n",
       "      <td>Mohanam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[-308.21133, 120.752266, 10.508814, 8.336225, ...</td>\n",
       "      <td>Mohanam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[-313.33838, 117.64787, 17.26717, 21.166502, 6...</td>\n",
       "      <td>Mohanam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[-311.86234, 116.409, 18.006712, 21.623466, 5....</td>\n",
       "      <td>Mohanam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[-310.63998, 125.96951, 15.492928, 19.149384, ...</td>\n",
       "      <td>Mohanam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[-169.67058, 96.48495, -66.12636, 43.346863, -...</td>\n",
       "      <td>Mohanam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[-155.1113, 56.9278, -52.016186, 39.760612, -2...</td>\n",
       "      <td>Mohanam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[-187.20172, 66.33403, -55.23273, 50.521683, -...</td>\n",
       "      <td>Mohanam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[-146.9628, 88.22245, -71.56997, 54.609814, -2...</td>\n",
       "      <td>Mohanam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[-323.00223, 95.03592, -51.75478, 6.7554083, -...</td>\n",
       "      <td>Mohanam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[-318.25247, 91.455414, -53.066055, 9.181376, ...</td>\n",
       "      <td>Mohanam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[-306.1751, 85.525764, -53.73121, 5.7814627, -...</td>\n",
       "      <td>Mohanam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[-353.21185, 119.59186, 24.895426, 25.061195, ...</td>\n",
       "      <td>Nata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[-334.3255, 98.12799, 24.627533, 23.619667, 4....</td>\n",
       "      <td>Nata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[-348.4952, 114.427605, 18.048315, 28.75373, 1...</td>\n",
       "      <td>Nata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[-169.45189, 79.42645, -64.57852, 58.774, -23....</td>\n",
       "      <td>Nata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[-177.13115, 85.14658, -64.99939, 53.943073, -...</td>\n",
       "      <td>Nata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[-355.67584, 125.1791, 18.90393, 27.903118, 2....</td>\n",
       "      <td>Nata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[-346.23193, 126.01379, 23.617458, 8.470036, -...</td>\n",
       "      <td>Nata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[-340.52994, 122.736664, 18.26399, 28.887371, ...</td>\n",
       "      <td>Nata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[-305.7635, 109.67052, 11.838475, 12.07011, -2...</td>\n",
       "      <td>Nata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[-298.6519, 112.5714, 8.725077, 7.9847956, -16...</td>\n",
       "      <td>Nata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[-355.63535, 116.9416, 28.144415, 26.806778, 6...</td>\n",
       "      <td>Nata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[-361.6717, 123.60966, 24.745937, 25.546164, 4...</td>\n",
       "      <td>Nata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[-351.00717, 120.8452, 15.672422, 35.007603, 9...</td>\n",
       "      <td>Nata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[-339.32803, 80.10002, -49.61237, 7.7818522, -...</td>\n",
       "      <td>Nata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[-349.57468, 83.12895, -50.074924, 9.405698, -...</td>\n",
       "      <td>Nata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[-347.8581, 81.89357, -48.651585, 9.595556, -1...</td>\n",
       "      <td>Nata</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              feature            class\n",
       "0   [-257.00793, 143.21645, -63.392902, 45.306725,...  Mayamalavagowla\n",
       "1   [-342.479, 121.16525, -28.796282, 44.39041, 14...  Mayamalavagowla\n",
       "2   [-265.17584, 147.72835, -59.28968, 47.248676, ...  Mayamalavagowla\n",
       "3   [-265.8661, 142.71452, -62.37273, 47.353455, 4...  Mayamalavagowla\n",
       "4   [-270.8769, 146.13509, -59.109337, 46.9478, 1....  Mayamalavagowla\n",
       "5   [-288.0216, 149.35812, -47.245678, 37.415783, ...  Mayamalavagowla\n",
       "6   [-354.0573, 141.69968, 26.293093, 13.852002, -...  Mayamalavagowla\n",
       "7   [-364.73254, 127.644356, 28.105154, 23.548061,...  Mayamalavagowla\n",
       "8   [-358.08014, 125.53306, 32.00193, 22.871235, -...  Mayamalavagowla\n",
       "9   [-358.75586, 140.48027, 27.321226, 9.683236, -...  Mayamalavagowla\n",
       "10  [-329.88388, 132.13698, 24.247555, 18.087626, ...  Mayamalavagowla\n",
       "11  [-301.8801, 77.61273, -43.964954, 6.8427114, -...  Mayamalavagowla\n",
       "12  [-310.87204, 68.62663, -43.044067, 2.4750962, ...  Mayamalavagowla\n",
       "13  [-302.76172, 74.42201, -47.095207, 5.852565, -...  Mayamalavagowla\n",
       "14  [-197.08652, 81.49152, -48.00849, 36.93677, -1...          Mohanam\n",
       "15  [-157.275, 95.572685, -55.988686, 30.901611, -...          Mohanam\n",
       "16  [-178.47586, 78.64402, -35.6453, 20.774988, -1...          Mohanam\n",
       "17  [-177.37201, 85.34112, -41.96415, 44.57123, -2...          Mohanam\n",
       "18  [-172.45381, 82.0647, -43.0798, 23.08912, -7.3...          Mohanam\n",
       "19  [-179.4202, 85.24829, -47.030994, 33.15376, -1...          Mohanam\n",
       "20  [-308.3186, 102.52005, 13.691593, 20.561224, 1...          Mohanam\n",
       "21  [-322.12534, 111.55545, 11.61951, 22.521864, 1...          Mohanam\n",
       "22  [-330.14243, 118.97464, 11.84664, 25.165697, 7...          Mohanam\n",
       "23  [-308.21133, 120.752266, 10.508814, 8.336225, ...          Mohanam\n",
       "24  [-313.33838, 117.64787, 17.26717, 21.166502, 6...          Mohanam\n",
       "25  [-311.86234, 116.409, 18.006712, 21.623466, 5....          Mohanam\n",
       "26  [-310.63998, 125.96951, 15.492928, 19.149384, ...          Mohanam\n",
       "27  [-169.67058, 96.48495, -66.12636, 43.346863, -...          Mohanam\n",
       "28  [-155.1113, 56.9278, -52.016186, 39.760612, -2...          Mohanam\n",
       "29  [-187.20172, 66.33403, -55.23273, 50.521683, -...          Mohanam\n",
       "30  [-146.9628, 88.22245, -71.56997, 54.609814, -2...          Mohanam\n",
       "31  [-323.00223, 95.03592, -51.75478, 6.7554083, -...          Mohanam\n",
       "32  [-318.25247, 91.455414, -53.066055, 9.181376, ...          Mohanam\n",
       "33  [-306.1751, 85.525764, -53.73121, 5.7814627, -...          Mohanam\n",
       "34  [-353.21185, 119.59186, 24.895426, 25.061195, ...             Nata\n",
       "35  [-334.3255, 98.12799, 24.627533, 23.619667, 4....             Nata\n",
       "36  [-348.4952, 114.427605, 18.048315, 28.75373, 1...             Nata\n",
       "37  [-169.45189, 79.42645, -64.57852, 58.774, -23....             Nata\n",
       "38  [-177.13115, 85.14658, -64.99939, 53.943073, -...             Nata\n",
       "39  [-355.67584, 125.1791, 18.90393, 27.903118, 2....             Nata\n",
       "40  [-346.23193, 126.01379, 23.617458, 8.470036, -...             Nata\n",
       "41  [-340.52994, 122.736664, 18.26399, 28.887371, ...             Nata\n",
       "42  [-305.7635, 109.67052, 11.838475, 12.07011, -2...             Nata\n",
       "43  [-298.6519, 112.5714, 8.725077, 7.9847956, -16...             Nata\n",
       "44  [-355.63535, 116.9416, 28.144415, 26.806778, 6...             Nata\n",
       "45  [-361.6717, 123.60966, 24.745937, 25.546164, 4...             Nata\n",
       "46  [-351.00717, 120.8452, 15.672422, 35.007603, 9...             Nata\n",
       "47  [-339.32803, 80.10002, -49.61237, 7.7818522, -...             Nata\n",
       "48  [-349.57468, 83.12895, -50.074924, 9.405698, -...             Nata\n",
       "49  [-347.8581, 81.89357, -48.651585, 9.595556, -1...             Nata"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# file='E:\\MCA-2 Year\\Main Project\\dataset\\Mayamalavagowla\\Mmg.wav'\n",
    "# audio, sample_rate = librosa.load(file)\n",
    "# mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "# mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
    "# print(\"mfccs\",mfccs_features)\n",
    "# print(\"mfccs scaled\",mfccs_scaled_features)\n",
    "\n",
    "\n",
    "def features_extractor(file):\n",
    "    audio, sample_rate = librosa.load(file)\n",
    "    mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "    mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
    "    return mfccs_scaled_features\n",
    "\n",
    "\n",
    "audio_path='E:\\MCA-2 Year\\Main Project\\dataset'\n",
    "extracted_features=[]\n",
    "for dirpath, dirnames, filenames in os.walk(audio_path):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('.wav'):\n",
    "                filepath=os.path.join(dirpath, filename)\n",
    "                label=filepath.replace(\"E:\\MCA-2 Year\\Main Project\\dataset\", '').replace(filename,\"\").replace('\\\\','')\n",
    "#                 print(filepath)\n",
    "                mfccs=features_extractor(filepath)\n",
    "                extracted_features.append([mfccs,label])\n",
    "                \n",
    "\n",
    "extracted_features_df=pd.DataFrame(extracted_features,columns=['feature','class'])\n",
    "extracted_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a5082b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split the dataset into independent and dependent dataset\n",
    "X=np.array(extracted_features_df['feature'].tolist())\n",
    "y=np.array(extracted_features_df['class'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "aa7e1e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Label Encoding\n",
    "###y=np.array(pd.get_dummies(y))\n",
    "### Label Encoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder=LabelEncoder()\n",
    "y=to_categorical(labelencoder.fit_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "bc2286a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "c2d1867c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 3)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d14e5fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "7992a48b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.55111298e+02,  5.69277992e+01, -5.20161858e+01,\n",
       "         3.97606125e+01, -2.30668774e+01,  1.15908365e+01,\n",
       "        -1.62758541e+01,  2.09192133e+00, -6.49271345e+00,\n",
       "         7.86300039e+00, -7.65429068e+00,  9.18413830e+00,\n",
       "        -4.27179003e+00,  1.43066511e+01, -6.02619553e+00,\n",
       "        -8.39855731e-01, -1.04500046e+01,  1.34619176e+00,\n",
       "        -1.10813293e+01, -3.01489878e+00, -5.95804882e+00,\n",
       "         1.55820203e+00, -1.28151524e+00,  1.67722836e+01,\n",
       "         3.38041639e+00,  1.07513046e+01, -1.30613089e+00,\n",
       "        -6.50946045e+00, -2.22519845e-01, -8.09815502e+00,\n",
       "        -6.67637873e+00,  2.36736941e+00, -2.70435023e+00,\n",
       "        -1.38272142e+00, -5.21208143e+00, -2.02848363e+00,\n",
       "        -4.47473526e+00, -2.05537009e+00,  1.78530037e+00,\n",
       "        -7.39262998e-01],\n",
       "       [-3.01880096e+02,  7.76127319e+01, -4.39649544e+01,\n",
       "         6.84271145e+00, -2.05005417e+01, -7.32769442e+00,\n",
       "        -3.37500420e+01,  1.69511855e+00, -1.29970293e+01,\n",
       "        -1.64801674e+01, -1.06581583e+01, -7.26737213e+00,\n",
       "         7.23022652e+00, -1.14873285e+01, -1.44047940e+00,\n",
       "        -1.67221987e+00, -6.73886955e-01, -3.89534974e+00,\n",
       "        -6.12488794e+00,  6.60995817e+00, -6.39382005e-01,\n",
       "        -6.70434952e+00, -1.14240570e+01, -4.43994856e+00,\n",
       "         4.43235111e+00,  7.63689995e+00,  6.91589165e+00,\n",
       "         4.33732605e+00, -3.35463858e+00, -7.62431717e+00,\n",
       "        -1.34689388e+01, -9.05819798e+00,  1.92828107e+00,\n",
       "        -4.05948073e-01, -2.50531387e+00, -2.94841790e+00,\n",
       "        -1.39942408e+00, -3.35268044e+00, -4.25274611e+00,\n",
       "        -1.09099209e+00],\n",
       "       [-3.29883881e+02,  1.32136978e+02,  2.42475548e+01,\n",
       "         1.80876255e+01, -1.42592192e+00, -1.84327946e+01,\n",
       "        -1.80605793e+01, -2.53082561e+00, -9.99187183e+00,\n",
       "        -8.09587860e+00,  1.86725521e+00, -7.06015062e+00,\n",
       "        -8.85997391e+00, -2.35747862e+00, -2.07994318e+00,\n",
       "        -1.19093170e+01, -8.97738457e+00,  4.84948063e+00,\n",
       "         4.03736621e-01, -2.24297071e+00, -2.48304868e+00,\n",
       "        -4.95254898e+00, -5.22868109e+00,  1.85657334e+00,\n",
       "         1.07535839e+00, -2.61040807e-01,  2.18937445e+00,\n",
       "         7.94069767e-01,  4.08928365e-01, -5.21930122e+00,\n",
       "        -6.59655142e+00,  1.42185903e+00, -1.05053353e+00,\n",
       "        -7.22645640e-01, -3.41541201e-01, -7.58062959e-01,\n",
       "        -8.85204136e-01, -1.00845456e+00, -1.26616609e+00,\n",
       "         1.58149564e+00],\n",
       "       [-3.40529938e+02,  1.22736664e+02,  1.82639904e+01,\n",
       "         2.88873711e+01, -1.87351894e+00, -5.91560888e+00,\n",
       "         6.22740555e+00, -9.11155701e+00, -1.81686935e+01,\n",
       "        -1.27523208e+00,  3.09942341e+00,  2.70010281e+00,\n",
       "         1.00443745e+01, -2.20002556e+00, -1.54747534e+00,\n",
       "         1.13339167e+01, -7.96814585e+00,  5.34302473e+00,\n",
       "        -4.64492607e+00, -4.94384480e+00, -1.93349111e+00,\n",
       "        -3.82909149e-01, -8.70089912e+00,  4.18980598e+00,\n",
       "        -6.52196598e+00, -2.01054192e+00, -2.03376746e+00,\n",
       "        -3.49091935e+00, -9.20983601e+00, -3.49261856e+00,\n",
       "        -6.24099541e+00, -2.14610808e-02, -2.95223355e+00,\n",
       "        -2.91675329e+00,  1.78902638e+00,  9.06368554e-01,\n",
       "        -1.76764953e+00,  2.64433646e+00,  3.65639114e+00,\n",
       "         2.11746693e+00],\n",
       "       [-2.65175842e+02,  1.47728348e+02, -5.92896805e+01,\n",
       "         4.72486763e+01, -4.76391435e-01,  9.25015926e-01,\n",
       "         1.41012793e+01, -4.72986031e+00,  2.08895278e+00,\n",
       "        -4.52892351e+00, -7.39641428e+00, -2.41766974e-01,\n",
       "        -7.72837925e+00, -9.11558056e+00, -7.40764093e+00,\n",
       "        -2.95670152e+00, -7.05272627e+00, -4.16178083e+00,\n",
       "        -2.45889235e+00, -7.91944408e+00, -5.25440025e+00,\n",
       "        -1.04027863e+01, -1.25949984e+01, -3.07255077e+00,\n",
       "        -7.55538285e-01,  2.81782913e+00,  6.89358282e+00,\n",
       "         5.38352489e+00,  1.72438419e+00, -9.62417126e+00,\n",
       "        -1.21605577e+01, -4.00812101e+00,  3.93612719e+00,\n",
       "         5.42321730e+00, -2.21389127e+00, -4.16579437e+00,\n",
       "        -2.56142378e+00, -4.68554449e+00,  3.82971376e-01,\n",
       "         5.41650724e+00],\n",
       "       [-1.69670578e+02,  9.64849472e+01, -6.61263580e+01,\n",
       "         4.33468628e+01, -2.04808884e+01,  1.10720158e+01,\n",
       "        -1.05762243e+01,  4.20736742e+00, -5.77022123e+00,\n",
       "         7.43236971e+00, -7.78836918e+00,  1.08844748e+01,\n",
       "        -1.96483827e+00, -7.38442183e-01, -5.68748808e+00,\n",
       "        -2.68573880e+00,  1.30531943e+00, -6.21761382e-01,\n",
       "        -2.35951948e+00, -7.81484318e+00, -8.71678352e+00,\n",
       "        -6.01129866e+00, -8.82074177e-01, -1.61610341e+00,\n",
       "        -3.05557919e+00,  8.78729761e-01, -7.03425121e+00,\n",
       "        -6.24370813e+00, -7.57243729e+00, -4.52013063e+00,\n",
       "        -4.85605288e+00,  1.37507367e+00,  6.90952480e-01,\n",
       "         9.13408375e+00,  2.96616340e+00,  8.97938728e-01,\n",
       "         1.93059361e+00, -1.28298473e+00, -4.90414667e+00,\n",
       "        -4.33462095e+00],\n",
       "       [-1.77131149e+02,  8.51465836e+01, -6.49993896e+01,\n",
       "         5.39430733e+01, -1.54115763e+01,  6.36526012e+00,\n",
       "        -7.46114779e+00,  1.26866360e+01, -1.12683306e+01,\n",
       "         6.02214241e+00, -7.71486568e+00,  7.40448999e+00,\n",
       "        -1.53464556e+00,  1.82159185e-01, -1.19964933e+00,\n",
       "        -3.21913266e+00, -3.03137445e+00, -5.22183418e+00,\n",
       "        -1.22704840e+00, -3.97378373e+00, -1.25861359e+01,\n",
       "        -5.14053440e+00, -1.08999491e+01, -4.59759378e+00,\n",
       "        -1.00247536e+01,  1.33874726e+00, -1.85619891e+00,\n",
       "         3.34729624e+00, -1.80722153e+00, -2.73573995e+00,\n",
       "        -8.75167465e+00,  5.39183855e-01, -4.19141531e+00,\n",
       "         2.50405622e+00,  3.84563297e-01,  5.91745496e-01,\n",
       "        -2.61731327e-01,  3.87034512e+00,  1.10260999e+00,\n",
       "        -8.15143347e-01],\n",
       "       [-3.23002228e+02,  9.50359192e+01, -5.17547798e+01,\n",
       "         6.75540829e+00, -1.86899643e+01, -1.00017252e+01,\n",
       "        -3.09974594e+01, -3.55192333e-01, -1.02545195e+01,\n",
       "        -1.70938931e+01, -1.08304415e+01, -4.09316111e+00,\n",
       "         6.38047791e+00, -1.18354368e+01,  4.59756994e+00,\n",
       "         1.54194367e+00,  6.12147093e-01, -5.25923824e+00,\n",
       "        -1.35388508e+01,  8.44575286e-01,  1.67578554e+00,\n",
       "        -3.91621590e-01, -7.83972597e+00, -8.17123532e-01,\n",
       "         1.73442221e+00, -2.01866925e-01,  4.22877407e+00,\n",
       "         3.04521751e+00, -8.09176385e-01, -2.96510625e+00,\n",
       "        -7.79422760e+00, -7.44442558e+00,  9.67958450e-01,\n",
       "        -1.23215830e+00, -2.82993293e+00, -2.06407666e+00,\n",
       "        -5.97469568e+00, -3.50453615e+00, -2.23901200e+00,\n",
       "        -3.86241961e+00],\n",
       "       [-3.30142426e+02,  1.18974640e+02,  1.18466396e+01,\n",
       "         2.51656971e+01,  7.11579037e+00,  4.38879013e+00,\n",
       "         1.25575972e+00, -8.86307621e+00, -1.63844452e+01,\n",
       "         1.17625885e+01, -3.13235450e+00,  2.42453361e+00,\n",
       "         5.63320398e+00,  4.34276372e-01,  5.45742571e-01,\n",
       "         8.55163097e+00, -1.14720774e+01,  1.24674044e+01,\n",
       "        -8.53198528e-01, -5.17774391e+00, -9.04146731e-01,\n",
       "        -2.84465814e+00, -8.98608875e+00,  4.12781954e+00,\n",
       "        -3.29227901e+00, -4.98058128e+00, -4.98369408e+00,\n",
       "        -3.92324448e+00, -2.68892312e+00,  2.33378339e+00,\n",
       "        -3.67974138e+00,  9.16797698e-01, -1.25021899e+00,\n",
       "        -3.10131264e+00,  2.13127136e+00,  3.18190247e-01,\n",
       "        -2.56773257e+00, -2.50136805e+00, -3.07609129e+00,\n",
       "         4.51477945e-01],\n",
       "       [-2.70876892e+02,  1.46135086e+02, -5.91093369e+01,\n",
       "         4.69477997e+01,  1.28271925e+00, -1.67187333e+00,\n",
       "         1.10499010e+01, -4.10806942e+00,  3.60418844e+00,\n",
       "        -4.80361557e+00, -7.84367990e+00, -6.57975149e+00,\n",
       "        -5.15682030e+00, -1.24751151e+00, -7.90798092e+00,\n",
       "        -7.79326391e+00, -9.36859894e+00, -8.04677296e+00,\n",
       "        -1.53549862e+00, -5.19518185e+00, -6.75499439e+00,\n",
       "        -1.10904036e+01, -1.04929628e+01, -3.41311145e+00,\n",
       "        -2.69854283e+00,  2.51571774e+00,  5.10295630e+00,\n",
       "         1.32945871e+00,  4.22168791e-01, -7.82874060e+00,\n",
       "        -1.37501116e+01, -3.93581223e+00,  4.48043394e+00,\n",
       "         2.52989912e+00, -2.83420105e-02, -1.43688214e+00,\n",
       "        -2.17960882e+00, -8.33810389e-01,  1.60749769e+00,\n",
       "         6.46398449e+00]], dtype=float32)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "92f821bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-306.1751    ,   85.525764  ,  -53.73121   , ...,   -3.7955704 ,\n",
       "          -3.726216  ,   -5.1125774 ],\n",
       "       [-334.3255    ,   98.12799   ,   24.627533  , ...,   -2.796529  ,\n",
       "          -5.6363254 ,   -2.1828659 ],\n",
       "       [-310.63998   ,  125.96951   ,   15.492928  , ...,   -0.80832416,\n",
       "          -1.2310495 ,    1.0921549 ],\n",
       "       ...,\n",
       "       [-257.00793   ,  143.21645   ,  -63.392902  , ...,   -0.94029754,\n",
       "           2.4364781 ,    5.905712  ],\n",
       "       [-339.32803   ,   80.10002   ,  -49.61237   , ...,   -6.2079253 ,\n",
       "          -4.073739  ,    2.0393324 ],\n",
       "       [-355.63535   ,  116.9416    ,   28.144415  , ...,   -2.1649451 ,\n",
       "          -2.5114498 ,   -1.4634374 ]], dtype=float32)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "841a7c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c128ace3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 3)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "60c33e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 3)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "fa44dc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ac35c9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "26c7c9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### No of classes\n",
    "num_labels=y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "befb51aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "e498cc19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "20ad5c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "###first layer\n",
    "model.add(Dense(100,input_shape=(40,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "###second layer\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "###third layer\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "###final layer\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "5feece93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "06d81ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "9ebedf64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5185 - accuracy: 0.7188\n",
      "Epoch 1: val_loss improved from inf to 0.57609, saving model to saved_models\\audio_classification.hdf5\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.5194 - accuracy: 0.7750 - val_loss: 0.5761 - val_accuracy: 0.7000\n",
      "Epoch 2/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3753 - accuracy: 0.7812\n",
      "Epoch 2: val_loss did not improve from 0.57609\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.4424 - accuracy: 0.7500 - val_loss: 0.5762 - val_accuracy: 0.7000\n",
      "Epoch 3/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6023 - accuracy: 0.7188\n",
      "Epoch 3: val_loss improved from 0.57609 to 0.57461, saving model to saved_models\\audio_classification.hdf5\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5924 - accuracy: 0.7250 - val_loss: 0.5746 - val_accuracy: 0.7000\n",
      "Epoch 4/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5819 - accuracy: 0.7500\n",
      "Epoch 4: val_loss improved from 0.57461 to 0.57350, saving model to saved_models\\audio_classification.hdf5\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5649 - accuracy: 0.7500 - val_loss: 0.5735 - val_accuracy: 0.7000\n",
      "Epoch 5/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6099 - accuracy: 0.7500\n",
      "Epoch 5: val_loss improved from 0.57350 to 0.57324, saving model to saved_models\\audio_classification.hdf5\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6394 - accuracy: 0.7000 - val_loss: 0.5732 - val_accuracy: 0.7000\n",
      "Epoch 6/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5631 - accuracy: 0.7188\n",
      "Epoch 6: val_loss did not improve from 0.57324\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.5174 - accuracy: 0.7500 - val_loss: 0.5745 - val_accuracy: 0.7000\n",
      "Epoch 7/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4945 - accuracy: 0.7812\n",
      "Epoch 7: val_loss did not improve from 0.57324\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.5656 - accuracy: 0.7750 - val_loss: 0.5755 - val_accuracy: 0.7000\n",
      "Epoch 8/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4822 - accuracy: 0.7500\n",
      "Epoch 8: val_loss did not improve from 0.57324\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.4150 - accuracy: 0.8000 - val_loss: 0.5767 - val_accuracy: 0.7000\n",
      "Epoch 9/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5735 - accuracy: 0.7188\n",
      "Epoch 9: val_loss did not improve from 0.57324\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.5074 - accuracy: 0.7500 - val_loss: 0.5796 - val_accuracy: 0.7000\n",
      "Epoch 10/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5194 - accuracy: 0.7812\n",
      "Epoch 10: val_loss did not improve from 0.57324\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.5145 - accuracy: 0.7750 - val_loss: 0.5828 - val_accuracy: 0.7000\n",
      "Epoch 11/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4896 - accuracy: 0.8438\n",
      "Epoch 11: val_loss did not improve from 0.57324\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.5586 - accuracy: 0.7750 - val_loss: 0.5869 - val_accuracy: 0.7000\n",
      "Epoch 12/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4786 - accuracy: 0.7812\n",
      "Epoch 12: val_loss did not improve from 0.57324\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.4886 - accuracy: 0.7500 - val_loss: 0.5878 - val_accuracy: 0.7000\n",
      "Epoch 13/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7504 - accuracy: 0.7188\n",
      "Epoch 13: val_loss did not improve from 0.57324\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.6397 - accuracy: 0.7500 - val_loss: 0.5860 - val_accuracy: 0.7000\n",
      "Epoch 14/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4842 - accuracy: 0.7812\n",
      "Epoch 14: val_loss did not improve from 0.57324\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.5083 - accuracy: 0.7500 - val_loss: 0.5853 - val_accuracy: 0.7000\n",
      "Epoch 15/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6277 - accuracy: 0.7500\n",
      "Epoch 15: val_loss did not improve from 0.57324\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.6074 - accuracy: 0.7750 - val_loss: 0.5853 - val_accuracy: 0.7000\n",
      "Epoch 16/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5092 - accuracy: 0.7188\n",
      "Epoch 16: val_loss did not improve from 0.57324\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.5217 - accuracy: 0.7250 - val_loss: 0.5847 - val_accuracy: 0.7000\n",
      "Epoch 17/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6108 - accuracy: 0.7812\n",
      "Epoch 17: val_loss did not improve from 0.57324\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.5854 - accuracy: 0.8000 - val_loss: 0.5812 - val_accuracy: 0.7000\n",
      "Epoch 18/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4843 - accuracy: 0.8750\n",
      "Epoch 18: val_loss did not improve from 0.57324\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.4518 - accuracy: 0.9000 - val_loss: 0.5780 - val_accuracy: 0.7000\n",
      "Epoch 19/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5191 - accuracy: 0.6875\n",
      "Epoch 19: val_loss improved from 0.57324 to 0.57239, saving model to saved_models\\audio_classification.hdf5\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5241 - accuracy: 0.7000 - val_loss: 0.5724 - val_accuracy: 0.7000\n",
      "Epoch 20/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5117 - accuracy: 0.7812\n",
      "Epoch 20: val_loss improved from 0.57239 to 0.56681, saving model to saved_models\\audio_classification.hdf5\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5060 - accuracy: 0.7500 - val_loss: 0.5668 - val_accuracy: 0.7000\n",
      "Epoch 21/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5412 - accuracy: 0.7188\n",
      "Epoch 21: val_loss improved from 0.56681 to 0.56242, saving model to saved_models\\audio_classification.hdf5\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5167 - accuracy: 0.7500 - val_loss: 0.5624 - val_accuracy: 0.7000\n",
      "Epoch 22/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6172 - accuracy: 0.7188\n",
      "Epoch 22: val_loss improved from 0.56242 to 0.55463, saving model to saved_models\\audio_classification.hdf5\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6114 - accuracy: 0.7500 - val_loss: 0.5546 - val_accuracy: 0.7000\n",
      "Epoch 23/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6278 - accuracy: 0.7188\n",
      "Epoch 23: val_loss improved from 0.55463 to 0.55045, saving model to saved_models\\audio_classification.hdf5\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5618 - accuracy: 0.7500 - val_loss: 0.5505 - val_accuracy: 0.7000\n",
      "Epoch 24/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5514 - accuracy: 0.8125\n",
      "Epoch 24: val_loss improved from 0.55045 to 0.54913, saving model to saved_models\\audio_classification.hdf5\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5525 - accuracy: 0.7750 - val_loss: 0.5491 - val_accuracy: 0.7000\n",
      "Epoch 25/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5671 - accuracy: 0.7500\n",
      "Epoch 25: val_loss improved from 0.54913 to 0.54787, saving model to saved_models\\audio_classification.hdf5\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5576 - accuracy: 0.7750 - val_loss: 0.5479 - val_accuracy: 0.7000\n",
      "Epoch 26/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5583 - accuracy: 0.6562\n",
      "Epoch 26: val_loss did not improve from 0.54787\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.5823 - accuracy: 0.6500 - val_loss: 0.5481 - val_accuracy: 0.7000\n",
      "Epoch 27/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5472 - accuracy: 0.7188\n",
      "Epoch 27: val_loss did not improve from 0.54787\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.4964 - accuracy: 0.7750 - val_loss: 0.5510 - val_accuracy: 0.7000\n",
      "Epoch 28/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6456 - accuracy: 0.6875\n",
      "Epoch 28: val_loss did not improve from 0.54787\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7241 - accuracy: 0.6500 - val_loss: 0.5526 - val_accuracy: 0.7000\n",
      "Epoch 29/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5646 - accuracy: 0.6875\n",
      "Epoch 29: val_loss did not improve from 0.54787\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.5353 - accuracy: 0.7000 - val_loss: 0.5544 - val_accuracy: 0.7000\n",
      "Epoch 30/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5132 - accuracy: 0.7812\n",
      "Epoch 30: val_loss did not improve from 0.54787\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.5532 - accuracy: 0.7500 - val_loss: 0.5528 - val_accuracy: 0.7000\n",
      "Epoch 31/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4019 - accuracy: 0.8125\n",
      "Epoch 31: val_loss did not improve from 0.54787\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3885 - accuracy: 0.8000 - val_loss: 0.5499 - val_accuracy: 0.7000\n",
      "Epoch 32/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4549 - accuracy: 0.7812\n",
      "Epoch 32: val_loss improved from 0.54787 to 0.54748, saving model to saved_models\\audio_classification.hdf5\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4824 - accuracy: 0.7750 - val_loss: 0.5475 - val_accuracy: 0.7000\n",
      "Epoch 33/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6558 - accuracy: 0.7812\n",
      "Epoch 33: val_loss improved from 0.54748 to 0.54411, saving model to saved_models\\audio_classification.hdf5\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6493 - accuracy: 0.7750 - val_loss: 0.5441 - val_accuracy: 0.7000\n",
      "Epoch 34/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5440 - accuracy: 0.7188\n",
      "Epoch 34: val_loss improved from 0.54411 to 0.54001, saving model to saved_models\\audio_classification.hdf5\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6553 - accuracy: 0.6750 - val_loss: 0.5400 - val_accuracy: 0.7000\n",
      "Epoch 35/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6606 - accuracy: 0.6250\n",
      "Epoch 35: val_loss improved from 0.54001 to 0.53683, saving model to saved_models\\audio_classification.hdf5\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6229 - accuracy: 0.6500 - val_loss: 0.5368 - val_accuracy: 0.7000\n",
      "Epoch 36/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3777 - accuracy: 0.8750\n",
      "Epoch 36: val_loss improved from 0.53683 to 0.53320, saving model to saved_models\\audio_classification.hdf5\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.3790 - accuracy: 0.8500 - val_loss: 0.5332 - val_accuracy: 0.8000\n",
      "Epoch 37/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4309 - accuracy: 0.8750\n",
      "Epoch 37: val_loss improved from 0.53320 to 0.53088, saving model to saved_models\\audio_classification.hdf5\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.3729 - accuracy: 0.9000 - val_loss: 0.5309 - val_accuracy: 0.8000\n",
      "Epoch 38/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4584 - accuracy: 0.8438\n",
      "Epoch 38: val_loss improved from 0.53088 to 0.52875, saving model to saved_models\\audio_classification.hdf5\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4599 - accuracy: 0.8500 - val_loss: 0.5287 - val_accuracy: 0.8000\n",
      "Epoch 39/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4714 - accuracy: 0.8438\n",
      "Epoch 39: val_loss improved from 0.52875 to 0.52523, saving model to saved_models\\audio_classification.hdf5\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4296 - accuracy: 0.8750 - val_loss: 0.5252 - val_accuracy: 0.8000\n",
      "Epoch 40/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4831 - accuracy: 0.7188\n",
      "Epoch 40: val_loss improved from 0.52523 to 0.52013, saving model to saved_models\\audio_classification.hdf5\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4574 - accuracy: 0.7500 - val_loss: 0.5201 - val_accuracy: 0.8000\n",
      "Epoch 41/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4013 - accuracy: 0.8750\n",
      "Epoch 41: val_loss improved from 0.52013 to 0.51533, saving model to saved_models\\audio_classification.hdf5\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.3933 - accuracy: 0.8750 - val_loss: 0.5153 - val_accuracy: 0.8000\n",
      "Epoch 42/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3779 - accuracy: 0.8125\n",
      "Epoch 42: val_loss improved from 0.51533 to 0.51121, saving model to saved_models\\audio_classification.hdf5\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4019 - accuracy: 0.8250 - val_loss: 0.5112 - val_accuracy: 0.8000\n",
      "Epoch 43/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2754 - accuracy: 0.9375\n",
      "Epoch 43: val_loss improved from 0.51121 to 0.50469, saving model to saved_models\\audio_classification.hdf5\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3099 - accuracy: 0.9250 - val_loss: 0.5047 - val_accuracy: 0.8000\n",
      "Epoch 44/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4009 - accuracy: 0.9062\n",
      "Epoch 44: val_loss improved from 0.50469 to 0.49660, saving model to saved_models\\audio_classification.hdf5\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.3884 - accuracy: 0.9250 - val_loss: 0.4966 - val_accuracy: 0.8000\n",
      "Epoch 45/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4540 - accuracy: 0.8125\n",
      "Epoch 45: val_loss improved from 0.49660 to 0.49093, saving model to saved_models\\audio_classification.hdf5\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4853 - accuracy: 0.7750 - val_loss: 0.4909 - val_accuracy: 0.8000\n",
      "Epoch 46/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4647 - accuracy: 0.7812\n",
      "Epoch 46: val_loss improved from 0.49093 to 0.48782, saving model to saved_models\\audio_classification.hdf5\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4304 - accuracy: 0.8000 - val_loss: 0.4878 - val_accuracy: 0.8000\n",
      "Epoch 47/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3787 - accuracy: 0.9062\n",
      "Epoch 47: val_loss improved from 0.48782 to 0.48434, saving model to saved_models\\audio_classification.hdf5\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.3685 - accuracy: 0.9000 - val_loss: 0.4843 - val_accuracy: 0.8000\n",
      "Epoch 48/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4487 - accuracy: 0.8750\n",
      "Epoch 48: val_loss improved from 0.48434 to 0.48285, saving model to saved_models\\audio_classification.hdf5\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.3803 - accuracy: 0.9000 - val_loss: 0.4828 - val_accuracy: 0.8000\n",
      "Epoch 49/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4818 - accuracy: 0.7812\n",
      "Epoch 49: val_loss did not improve from 0.48285\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.5555 - accuracy: 0.7750 - val_loss: 0.4846 - val_accuracy: 0.8000\n",
      "Epoch 50/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4574 - accuracy: 0.7812\n",
      "Epoch 50: val_loss did not improve from 0.48285\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.4268 - accuracy: 0.8250 - val_loss: 0.4869 - val_accuracy: 0.7000\n",
      "Epoch 51/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4598 - accuracy: 0.8750\n",
      "Epoch 51: val_loss did not improve from 0.48285\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.4330 - accuracy: 0.9000 - val_loss: 0.4896 - val_accuracy: 0.7000\n",
      "Epoch 52/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4000 - accuracy: 0.9062\n",
      "Epoch 52: val_loss did not improve from 0.48285\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.3889 - accuracy: 0.9000 - val_loss: 0.4917 - val_accuracy: 0.7000\n",
      "Epoch 53/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6408 - accuracy: 0.7500\n",
      "Epoch 53: val_loss did not improve from 0.48285\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.5682 - accuracy: 0.7750 - val_loss: 0.4935 - val_accuracy: 0.7000\n",
      "Epoch 54/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5094 - accuracy: 0.7500\n",
      "Epoch 54: val_loss did not improve from 0.48285\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.5210 - accuracy: 0.7500 - val_loss: 0.4959 - val_accuracy: 0.7000\n",
      "Epoch 55/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2684 - accuracy: 0.9062\n",
      "Epoch 55: val_loss did not improve from 0.48285\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.3752 - accuracy: 0.8500 - val_loss: 0.4991 - val_accuracy: 0.7000\n",
      "Epoch 56/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4038 - accuracy: 0.7812\n",
      "Epoch 56: val_loss did not improve from 0.48285\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.4384 - accuracy: 0.8000 - val_loss: 0.5045 - val_accuracy: 0.7000\n",
      "Epoch 57/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4880 - accuracy: 0.7812\n",
      "Epoch 57: val_loss did not improve from 0.48285\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.4421 - accuracy: 0.8250 - val_loss: 0.5111 - val_accuracy: 0.7000\n",
      "Epoch 58/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4925 - accuracy: 0.7812\n",
      "Epoch 58: val_loss did not improve from 0.48285\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.5041 - accuracy: 0.7750 - val_loss: 0.5171 - val_accuracy: 0.7000\n",
      "Epoch 59/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4180 - accuracy: 0.8438\n",
      "Epoch 59: val_loss did not improve from 0.48285\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.4571 - accuracy: 0.8000 - val_loss: 0.5208 - val_accuracy: 0.7000\n",
      "Epoch 60/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4955 - accuracy: 0.7188\n",
      "Epoch 60: val_loss did not improve from 0.48285\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.4330 - accuracy: 0.7750 - val_loss: 0.5228 - val_accuracy: 0.8000\n",
      "Epoch 61/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4523 - accuracy: 0.8438\n",
      "Epoch 61: val_loss did not improve from 0.48285\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.3976 - accuracy: 0.8750 - val_loss: 0.5202 - val_accuracy: 0.9000\n",
      "Epoch 62/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3933 - accuracy: 0.8125\n",
      "Epoch 62: val_loss did not improve from 0.48285\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.4136 - accuracy: 0.7750 - val_loss: 0.5180 - val_accuracy: 0.9000\n",
      "Epoch 63/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4106 - accuracy: 0.8438\n",
      "Epoch 63: val_loss did not improve from 0.48285\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.4050 - accuracy: 0.8500 - val_loss: 0.5161 - val_accuracy: 0.9000\n",
      "Epoch 64/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4269 - accuracy: 0.8438\n",
      "Epoch 64: val_loss did not improve from 0.48285\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.4682 - accuracy: 0.7750 - val_loss: 0.5158 - val_accuracy: 0.9000\n",
      "Epoch 65/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4025 - accuracy: 0.7500\n",
      "Epoch 65: val_loss did not improve from 0.48285\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.3865 - accuracy: 0.7750 - val_loss: 0.5161 - val_accuracy: 0.9000\n",
      "Epoch 66/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6143 - accuracy: 0.8125\n",
      "Epoch 66: val_loss did not improve from 0.48285\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.5334 - accuracy: 0.8250 - val_loss: 0.5152 - val_accuracy: 0.9000\n",
      "Epoch 67/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3685 - accuracy: 0.8438\n",
      "Epoch 67: val_loss did not improve from 0.48285\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.3794 - accuracy: 0.8250 - val_loss: 0.5127 - val_accuracy: 0.9000\n",
      "Epoch 68/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5098 - accuracy: 0.7812\n",
      "Epoch 68: val_loss did not improve from 0.48285\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.4442 - accuracy: 0.8250 - val_loss: 0.5084 - val_accuracy: 0.9000\n",
      "Epoch 69/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5433 - accuracy: 0.8125\n",
      "Epoch 69: val_loss did not improve from 0.48285\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.4888 - accuracy: 0.8000 - val_loss: 0.5064 - val_accuracy: 0.9000\n",
      "Epoch 70/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2235 - accuracy: 0.9375\n",
      "Epoch 70: val_loss did not improve from 0.48285\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.2732 - accuracy: 0.9250 - val_loss: 0.5060 - val_accuracy: 0.9000\n",
      "Epoch 71/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3358 - accuracy: 0.8750\n",
      "Epoch 71: val_loss did not improve from 0.48285\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.3958 - accuracy: 0.8500 - val_loss: 0.5067 - val_accuracy: 0.9000\n",
      "Epoch 72/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4010 - accuracy: 0.8438\n",
      "Epoch 72: val_loss did not improve from 0.48285\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.3804 - accuracy: 0.8500 - val_loss: 0.5068 - val_accuracy: 0.9000\n",
      "Epoch 73/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3339 - accuracy: 0.8438\n",
      "Epoch 73: val_loss did not improve from 0.48285\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.3003 - accuracy: 0.8750 - val_loss: 0.5074 - val_accuracy: 0.9000\n",
      "Epoch 74/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3438 - accuracy: 0.8750\n",
      "Epoch 74: val_loss did not improve from 0.48285\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.3456 - accuracy: 0.8500 - val_loss: 0.5081 - val_accuracy: 0.9000\n",
      "Epoch 75/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2787 - accuracy: 0.8750\n",
      "Epoch 75: val_loss did not improve from 0.48285\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.3268 - accuracy: 0.8250 - val_loss: 0.5093 - val_accuracy: 0.9000\n",
      "Epoch 76/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3905 - accuracy: 0.8750\n",
      "Epoch 76: val_loss did not improve from 0.48285\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.3899 - accuracy: 0.9000 - val_loss: 0.5120 - val_accuracy: 0.9000\n",
      "Epoch 77/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5861 - accuracy: 0.7188\n",
      "Epoch 77: val_loss did not improve from 0.48285\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.5219 - accuracy: 0.7500 - val_loss: 0.5087 - val_accuracy: 0.9000\n",
      "Epoch 78/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4467 - accuracy: 0.7500\n",
      "Epoch 78: val_loss did not improve from 0.48285\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.4655 - accuracy: 0.7250 - val_loss: 0.5060 - val_accuracy: 0.9000\n",
      "Epoch 79/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1857 - accuracy: 0.9688\n",
      "Epoch 79: val_loss did not improve from 0.48285\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.3066 - accuracy: 0.8750 - val_loss: 0.5020 - val_accuracy: 0.9000\n",
      "Epoch 80/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3359 - accuracy: 0.8750\n",
      "Epoch 80: val_loss did not improve from 0.48285\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.3238 - accuracy: 0.9000 - val_loss: 0.5006 - val_accuracy: 0.9000\n",
      "Epoch 81/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4999 - accuracy: 0.7500\n",
      "Epoch 81: val_loss did not improve from 0.48285\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.5143 - accuracy: 0.7500 - val_loss: 0.5009 - val_accuracy: 0.9000\n",
      "Epoch 82/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5492 - accuracy: 0.7500\n",
      "Epoch 82: val_loss did not improve from 0.48285\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.5759 - accuracy: 0.7250 - val_loss: 0.4974 - val_accuracy: 0.9000\n",
      "Epoch 83/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4011 - accuracy: 0.8438\n",
      "Epoch 83: val_loss did not improve from 0.48285\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.3722 - accuracy: 0.8500 - val_loss: 0.4926 - val_accuracy: 0.9000\n",
      "Epoch 84/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3908 - accuracy: 0.8125\n",
      "Epoch 84: val_loss did not improve from 0.48285\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.4126 - accuracy: 0.8000 - val_loss: 0.4901 - val_accuracy: 0.9000\n",
      "Epoch 85/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4692 - accuracy: 0.8438\n",
      "Epoch 85: val_loss did not improve from 0.48285\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.4161 - accuracy: 0.8500 - val_loss: 0.4896 - val_accuracy: 0.9000\n",
      "Epoch 86/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5290 - accuracy: 0.7812\n",
      "Epoch 86: val_loss did not improve from 0.48285\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.4776 - accuracy: 0.8000 - val_loss: 0.4859 - val_accuracy: 0.9000\n",
      "Epoch 87/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2804 - accuracy: 0.9062\n",
      "Epoch 87: val_loss did not improve from 0.48285\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.3263 - accuracy: 0.8500 - val_loss: 0.4830 - val_accuracy: 0.9000\n",
      "Epoch 88/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3689 - accuracy: 0.8125\n",
      "Epoch 88: val_loss improved from 0.48285 to 0.48113, saving model to saved_models\\audio_classification.hdf5\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.3775 - accuracy: 0.8250 - val_loss: 0.4811 - val_accuracy: 0.9000\n",
      "Epoch 89/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3652 - accuracy: 0.8438\n",
      "Epoch 89: val_loss improved from 0.48113 to 0.48074, saving model to saved_models\\audio_classification.hdf5\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.3371 - accuracy: 0.8500 - val_loss: 0.4807 - val_accuracy: 0.9000\n",
      "Epoch 90/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3628 - accuracy: 0.8438\n",
      "Epoch 90: val_loss improved from 0.48074 to 0.47990, saving model to saved_models\\audio_classification.hdf5\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3413 - accuracy: 0.8250 - val_loss: 0.4799 - val_accuracy: 0.9000\n",
      "Epoch 91/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4491 - accuracy: 0.8125\n",
      "Epoch 91: val_loss improved from 0.47990 to 0.47694, saving model to saved_models\\audio_classification.hdf5\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4694 - accuracy: 0.8000 - val_loss: 0.4769 - val_accuracy: 0.9000\n",
      "Epoch 92/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3970 - accuracy: 0.7812\n",
      "Epoch 92: val_loss improved from 0.47694 to 0.47418, saving model to saved_models\\audio_classification.hdf5\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.3833 - accuracy: 0.8250 - val_loss: 0.4742 - val_accuracy: 0.9000\n",
      "Epoch 93/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3296 - accuracy: 0.8125\n",
      "Epoch 93: val_loss improved from 0.47418 to 0.47385, saving model to saved_models\\audio_classification.hdf5\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.2969 - accuracy: 0.8500 - val_loss: 0.4738 - val_accuracy: 0.9000\n",
      "Epoch 94/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3216 - accuracy: 0.8438\n",
      "Epoch 94: val_loss did not improve from 0.47385\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.2962 - accuracy: 0.8750 - val_loss: 0.4769 - val_accuracy: 0.9000\n",
      "Epoch 95/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3183 - accuracy: 0.8750\n",
      "Epoch 95: val_loss did not improve from 0.47385\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.3287 - accuracy: 0.8500 - val_loss: 0.4801 - val_accuracy: 0.9000\n",
      "Epoch 96/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3249 - accuracy: 0.8438\n",
      "Epoch 96: val_loss did not improve from 0.47385\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.2986 - accuracy: 0.8750 - val_loss: 0.4832 - val_accuracy: 0.9000\n",
      "Epoch 97/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3731 - accuracy: 0.8750\n",
      "Epoch 97: val_loss did not improve from 0.47385\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.3831 - accuracy: 0.8750 - val_loss: 0.4840 - val_accuracy: 0.9000\n",
      "Epoch 98/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3466 - accuracy: 0.8750\n",
      "Epoch 98: val_loss did not improve from 0.47385\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.3232 - accuracy: 0.9000 - val_loss: 0.4847 - val_accuracy: 0.9000\n",
      "Epoch 99/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3793 - accuracy: 0.8125\n",
      "Epoch 99: val_loss did not improve from 0.47385\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.3445 - accuracy: 0.8250 - val_loss: 0.4881 - val_accuracy: 0.9000\n",
      "Epoch 100/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3194 - accuracy: 0.8438\n",
      "Epoch 100: val_loss did not improve from 0.47385\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.3328 - accuracy: 0.8500 - val_loss: 0.4909 - val_accuracy: 0.9000\n",
      "Training completed in time:  0:00:03.381642\n"
     ]
    }
   ],
   "source": [
    "## Trianing my model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime \n",
    "\n",
    "num_epochs = 100\n",
    "num_batch_size = 32\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/audio_classification.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "748c012a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8999999761581421\n"
     ]
    }
   ],
   "source": [
    "test_accuracy=model.evaluate(X_test,y_test,verbose=0)\n",
    "print(test_accuracy[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "3966b730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-301.8801    ,   77.61273   ,  -43.964954  ,    6.8427114 ,\n",
       "        -20.500542  ,   -7.3276944 ,  -33.750042  ,    1.6951185 ,\n",
       "        -12.997029  ,  -16.480167  ,  -10.658158  ,   -7.267372  ,\n",
       "          7.2302265 ,  -11.487329  ,   -1.4404794 ,   -1.6722199 ,\n",
       "         -0.67388695,   -3.8953497 ,   -6.124888  ,    6.609958  ,\n",
       "         -0.639382  ,   -6.7043495 ,  -11.424057  ,   -4.4399486 ,\n",
       "          4.432351  ,    7.6369    ,    6.9158916 ,    4.337326  ,\n",
       "         -3.3546386 ,   -7.624317  ,  -13.468939  ,   -9.058198  ,\n",
       "          1.9282811 ,   -0.40594807,   -2.5053139 ,   -2.948418  ,\n",
       "         -1.3994241 ,   -3.3526804 ,   -4.252746  ,   -1.0909921 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "8e338d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0],\n",
       "       [0, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0]])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "6d1960eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 48ms/step\n",
      "[2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Nata'], dtype='<U15')"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filename=\"E:\\MCA-2 Year\\Main Project\\dataset\\Mayamalavagowla\\Mmg.wav\"\n",
    "# audio, sample_rate = librosa.load(filename, res_type='kaiser_fast') \n",
    "# mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "# mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
    "import librosa\n",
    "# mfccs_scaled_features.shape\n",
    "filename=\"C:/Users/Akhilraj/Downloads/Natta10M.wav\"\n",
    "audio, sample_rate = librosa.load(filename, res_type='kaiser_fast') \n",
    "mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
    "\n",
    "# print(mfccs_scaled_features)\n",
    "mfccs_scaled_features=mfccs_scaled_features.reshape(1,-1)\n",
    "# print(mfccs_scaled_features)\n",
    "# print(mfccs_scaled_features.shape)\n",
    "predict_x=model.predict(mfccs_scaled_features) \n",
    "classes_x=np.argmax(predict_x,axis=1)\n",
    "print(classes_x)\n",
    "prediction_class = labelencoder.inverse_transform(classes_x) \n",
    "prediction_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "dd031657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mfccs_scaled_features=mfccs_scaled_features.reshape(1,-1)\n",
    "# print(mfccs_scaled_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "affff2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mfccs_scaled_features.shape\n",
    "# mfccs_scaled_features\n",
    "# X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "74ddb2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted_label=model.predict_class(mfccs_scaled_features)\n",
    "# print(predicted_label)\n",
    "# y_pred = model.predict(X_train)\n",
    "# X_test.shape\n",
    "# # 'y_pred' will be an array of predicted probabilities for each class in your output\n",
    "# # to get the predicted class for each input, you can use the 'argmax' function to find the index of the maximum probability in each row\n",
    "# y_pred_classes = y_pred.argmax(axis=-1)\n",
    "# y_pred_classes\n",
    "# a=labelencoder.inverse_transform(y_pred_classes)\n",
    "# a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14f7bef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6965ebe0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
